# Comparing Classifers Based on Cost-Benefit and ROC Curves

- ROC curve facilites comparing two classiers' performance visually
- Our objective is to increase true positive rate as well as decrease false positive rate
![]({{site.url}}/{{site.baseurl}}/assets/roc/roc_curve.png)
[Image taken from *Data Mining Concepts and Techniques, third edition*]

- $y=x$ represent the classifier which predict randomly, for every true positive it predict another false positive
- Convex hull is used to smooth ROC curve

- **Exercise 8.12 recommended**, suppose table data tuple are 1-9.

# Techniques to Improve Classification Accuracy

## Ensamble
## Bagging
![]({{site.url}}/{{site.baseurl}}/assets/roc/ensamble.png)
- $D1, D2,...$ may be bootstraping samples
- $M1, M2,...$ are different classification models
- upon new data, we take output from all the classifiers and make final decision with majority votes.
![]({{site.url}}/{{site.baseurl}}/assets/roc/single_vs_ensamble.png)

- Actual classes are linearly separable
- Left is the output of single decisiontree, right is the output of ensamble of decision trees.