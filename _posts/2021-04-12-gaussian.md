# Bivariate Relationship

## Covariance
<iframe width="560" height="315" src="https://www.youtube.com/embed/xGbpuFNR1ME" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

Covariance, Correlation, Linear Regression are strongly related.

Covariance characteristic:
- positive value indicates a direct or increasing linear relationship
- negative value indicates decreasing relationship
- zero indicates no relationship

$$\sigma_{xy} = \frac{\sum (x_i-\mu_x) (y_i-\mu_y)}{N}$$

## Covariance Matrix
Let's say we have four variables $x1, x2, x3, x4$, the covariance matrix will be

|-|x1|x2|x3|x4|
|---|---|---|---|---|
|x1|var(x1)|cov(x1,x2)|cov(x1,x3)|cov(x1,x4)|
|x2|cov(x2,x1)|var(x2)|cov(x2,x3)|cov(x2,x4)|
|x3|cov(x3,x1)|cov(x3,x2)|var(x3)|cov(x3,x4)|
|x4|cov(x4,x1)|cov(x4,x2)|cov(x4,x3)|var(x4)|

But covariance is transitive: cov(x1, x2) = cov(x2,x1).

So covariance matrix X: $X^T=X$

## Correlation

diff:

|Covariance|Correlation|
|---|---|
|Covariance provides the **DIRECTION** of the linear relationship|Correlation provides **DIRECTION** and **STRENGTH**|
|Covariance has no upper or lower bound and its size is dependent on the scale of the variable|Colleation is scaled version of covarience, is always $\[-1, 1\]$|
|Covarience is not standardized|Correlation is standardized|

Pearson correlation coefficient: $$r = \frac{cov(x,y)}{\sigma(x)\sigma(y)}$$

## Gaussian Processes
Let's say we have bivariate Gaussian distribution:
$$
\begin{bmatrix}
    x_1\\
    x_2
\end{bmatrix}
\sim
\mathcal{N}(
\begin{bmatrix}
    \mu_1\\
    \mu_2
\end{bmatrix},
\begin{bmatrix}
    \Sigma_{11} & \Sigma_{12}\\
    \Sigma_{21} & \Sigma_{22}
\end{bmatrix}
)
$$

In this case, $P(x_2\|x_1)$ will also be a gaussian distribution with mean $\mu_{1\|2}$ and varience $\Sigma_{1\|2}$.
Theorem says that:
$$\mu_{1\|2} = \mu_1 = \Sigma_{12}\Sigma_{22}^{-1}(x_2-\mu2)$$
$$\Sigma_{1\|2} = \Sigma_{11}-\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21}$$

This theorem allows us to go from joint Gaussian distribution to conditional Gaussian distribution.


$x_i \sim \mathcal{N}(\mu, \sigma^2) \sim \mu + \sigma \mathcal{N}(0,1)$